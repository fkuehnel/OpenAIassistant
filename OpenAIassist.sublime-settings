{
    // Your OpenAI token
    "token": "",

    // A list of customizable tasks
    "tasks": {
        "write": {
            // The model which will generate the text completion.
            "model": "gpt-3.5-turbo",

            // The maximum number of tokens to generate.
            // Requests can use up to 2,048 or 4,000 tokens shared between prompt and completion.
            // The exact limit varies by model.
            // (One token is roughly 4 characters for normal English text)
            // Does not affect editing mode.
            "max_tokens": 2048,

            // OpenAI communication API endpoint
            "api_endpoint": "/v1/chat/completions",

            // Controls randomness: Lowering results in less random completions.
            // As the temperature approaches zero, the model will become deterministic and repetitive.
            "temperature": 0.9,

            "actions": {
                "summarize": {
                    "prompt": "Summarize the following text in the same language. For short text only use 1 paragraph. For longer text use a maximum of 3 paragraphs.",
                    "show": "new_tab",
                },
                "expand": {
                    "prompt": "Rewrite this entire section and expand it to a few more paragraphs, be more explicit and descriptive using the same tone and language.",
                    "show": "new_tab",
                },
                "complete": {
                    "prompt": "Complete this section, write one or more paragraphs as needed. Use your creativity to complete it, but keept the same tone and language.",
                    "show": "add",
                },
                "rewrite_creative": {
                    "prompt": "Rewrite this section in roughly the same length, but use a more creative language and tone.",
                    "show": "replace"
                },
                "rewrite_balanced": {
                    "prompt": "Rewrite this section in the same length, but using a balanced tone.",
                    "show": "replace"
                },
                "rewrite_precise": {
                    "prompt": "Rewrite this section in the same length, but using a more precise and scientific tone.",
                    "show": "replace"
                }
            }
        },

        "text_edit": {
            // The model which will generate the text completion.
            "model": "text-davinci-edit-001",

            // OpenAI communication API endpoint
            "api_endpoint": "/v1/edits",

            // Controls randomness: Lowering results in less random completions.
            // As the temperature approaches zero, the model will become deterministic and repetitive.
            "temperature": 0.9,

            "actions": {
                "correct": {
                    "prompt": "Use the same language and DO NOT write other contents or sentences. Just correct the grammar and syntax in the text below, leave everything else as is!",
                    "show": "new_tab",
                },
            }
        },

        "code": {
            // The model which will generate the text completion.
            "model": "text-davinci-003",

            // The maximum number of tokens to generate.
            // Requests can use up to 2,048 or 4,000 tokens shared between prompt and completion.
            // The exact limit varies by model.
            // (One token is roughly 4 characters for normal English text)
            // Does not affect editing mode.
            "max_tokens": 3072,

            // OpenAI communication API endpoint
            "api_endpoint": "/v1/completions",

            // Controls randomness: Lowering results in less random completions.
            // As the temperature approaches zero, the model will become deterministic and repetitive.
            "temperature": 1.0,

            "actions": {
                "correct": {
                    "prompt": "Correct the mistakes and errors in the code",
                    "show": "new_tab",
                },
                "complete": {
                    "prompt": "Complete and finish this code",
                    "show": "add",
                },
                "analyze": {
                    "prompt": "Analyze and show your findings of problems in this code, insert the code snippets that show the problem in your answers, use multimarkdown markup language to do so.",
                    "show": "new_tab",
                },
            }
        }
    }
}